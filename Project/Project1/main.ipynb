{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit (conda)",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "fcdafa320b1bd52415b4da26a3e91d8c55e0b68a992d8fe533e9215398eb0247"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import 3rd party dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 280,
   "outputs": []
  },
  {
   "source": [
    "## Load training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data = pd.read_csv(\"archive/train.csv\")\n",
    "print(data)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 281,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n0               842     0          2.2         0   1       0           7   \n1              1021     1          0.5         1   0       1          53   \n2               563     1          0.5         1   2       1          41   \n3               615     1          2.5         0   0       0          10   \n4              1821     1          1.2         0  13       1          44   \n...             ...   ...          ...       ...  ..     ...         ...   \n1995            794     1          0.5         1   0       1           2   \n1996           1965     1          2.6         1   0       0          39   \n1997           1911     0          0.9         1   1       1          36   \n1998           1512     0          0.9         0   4       1          46   \n1999            510     1          2.0         1   5       1          45   \n\n      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n0       0.6        188        2  ...         20       756  2549     9     7   \n1       0.7        136        3  ...        905      1988  2631    17     3   \n2       0.9        145        5  ...       1263      1716  2603    11     2   \n3       0.8        131        6  ...       1216      1786  2769    16     8   \n4       0.6        141        2  ...       1208      1212  1411     8     2   \n...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n1995    0.8        106        6  ...       1222      1890   668    13     4   \n1996    0.2        187        4  ...        915      1965  2032    11    10   \n1997    0.7        108        8  ...        868      1632  3057     9     1   \n1998    0.1        145        5  ...        336       670   869    18    10   \n1999    0.9        168        6  ...        483       754  3919    19     4   \n\n      talk_time  three_g  touch_screen  wifi  price_range  \n0            19        0             0     1            1  \n1             7        1             1     0            2  \n2             9        1             1     0            2  \n3            11        1             0     0            2  \n4            15        1             1     0            1  \n...         ...      ...           ...   ...          ...  \n1995         19        1             1     0            0  \n1996         16        1             1     1            2  \n1997          5        1             1     0            3  \n1998         19        1             1     1            0  \n1999          2        1             1     1            3  \n\n[2000 rows x 21 columns]\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Convert labels into to two classes: low (0, 1) and high (2, 3)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n0            842     0          2.2         0   1       0           7    0.6   \n1           1021     1          0.5         1   0       1          53    0.7   \n2            563     1          0.5         1   2       1          41    0.9   \n3            615     1          2.5         0   0       0          10    0.8   \n4           1821     1          1.2         0  13       1          44    0.6   \n\n   mobile_wt  n_cores  ...  px_width   ram  sc_h  sc_w  talk_time  three_g  \\\n0        188        2  ...       756  2549     9     7         19        0   \n1        136        3  ...      1988  2631    17     3          7        1   \n2        145        5  ...      1716  2603    11     2          9        1   \n3        131        6  ...      1786  2769    16     8         11        1   \n4        141        2  ...      1212  1411     8     2         15        1   \n\n   touch_screen  wifi  price_range  price_classification  \n0             0     1            1                     0  \n1             1     0            2                     1  \n2             1     0            2                     1  \n3             0     0            2                     1  \n4             1     0            1                     0  \n\n[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data[\"price_classification\"] = np.where(data[\"price_range\"] <= 1, 0, 1)\n",
    "print(data.head())"
   ]
  },
  {
   "source": [
    "#### Split the original ‘train.csv’ into ‘train.csv’, ‘valid.csv’ and ‘test.csv’ with the ratio of 0.8 : 0.1 : 0.1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data\n",
    "y = data[\"price_range\"]\n",
    "train_data, tmp_x, train_y, tmp_y = train_test_split(x, y, test_size = 0.2, random_state = 101, stratify = y)\n",
    "test_data, valid_data, test_y, valid_y = train_test_split(tmp_x, tmp_y, test_size = 0.5, random_state = 101, stratify = tmp_y)"
   ]
  },
  {
   "source": [
    "#### Test whether the split works correctly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1600, 22)\n(200, 22)\n(200, 22)\n      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n1569           1494     0          2.4         0   6       1           3   \n1668            962     0          1.0         1  14       0           2   \n1989            586     0          2.8         0   2       0          15   \n1609           1148     0          2.3         1   0       1          58   \n1424           1352     0          2.4         0   5       1           6   \n\n      m_dep  mobile_wt  n_cores  ...  px_width   ram  sc_h  sc_w  talk_time  \\\n1569    0.9         93        7  ...      1003  1208    14    13         17   \n1668    0.9        125        1  ...      1916  1491    16     2         14   \n1989    0.2         83        3  ...       854  2592    12     8          3   \n1609    0.3        170        5  ...       688  3127    10     7         11   \n1424    0.9         92        6  ...      1299  1309    12     1         14   \n\n      three_g  touch_screen  wifi  price_range  price_classification  \n1569        1             1     0            1                     0  \n1668        1             0     0            1                     0  \n1989        0             0     0            1                     0  \n1609        1             0     0            2                     1  \n1424        1             0     0            1                     0  \n\n[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(train_data.head())"
   ]
  },
  {
   "source": [
    "#### Write the data back to the csv file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train.csv\")\n",
    "test_data.to_csv(\"test.csv\")\n",
    "valid_data.to_csv(\"valid.csv\")"
   ]
  },
  {
   "source": [
    "## Model Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### The Sigmoid function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 286,
   "outputs": []
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, learning_rate=.1, n_iterations=8000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def initialize_weights(self, n_features):\n",
    "        limit = np.sqrt(1 / n_features)\n",
    "        w = np.random.uniform(-limit, limit, (n_features, 1))\n",
    "        b = 0\n",
    "        # Insert 0 as w_0\n",
    "        self.w = np.insert(w, 0, b, axis=0)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        normal_X = normalize(X, norm = 'max')\n",
    "        m_samples, n_features = normal_X.shape\n",
    "        self.initialize_weights(n_features)\n",
    "        # Insert a column of 1 as x_0\n",
    "        normal_X = np.insert(normal_X, 0, 1, axis=1)\n",
    "        y = np.reshape(y, (m_samples, 1))\n",
    "        for i in range(self.n_iterations):\n",
    "            h_x = normal_X.dot(self.w)\n",
    "            y_pred = sigmoid(h_x)\n",
    "            w_grad = normal_X.T.dot(y_pred - y)\n",
    "            self.w = self.w - self.learning_rate * w_grad\n",
    "        return self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        normal_X = normalize(X, norm = 'max')\n",
    "        normal_X = np.insert(normal_X, 0, 1, axis=1)\n",
    "        h_x = normal_X.dot(self.w)\n",
    "        y_pred = np.round(sigmoid(h_x))\n",
    "        return y_pred.astype(int)\n",
    "\n",
    "    def test(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        right_count = 0\n",
    "        m_samples = X.shape[0]\n",
    "        for i in range(m_samples):\n",
    "            if y_pred[i] == y[i]:\n",
    "                right_count += 1\n",
    "        return right_count / m_samples "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 287,
   "outputs": []
  },
  {
   "source": [
    "### Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    def __init__(self, continuous, uncontinuous):\n",
    "        self.continuous = continuous\n",
    "        self.uncontinuous = uncontinuous\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = {}\n",
    "        for i, c in enumerate(self.classes):\n",
    "            # Calculate prior probability of every class\n",
    "            prior = y.values[np.where(self.y == c)].shape[0] / self.y.shape[0]\n",
    "            # Calculate likelihood of every continuous attribute\n",
    "            likelihood_con = {}\n",
    "            for item in self.continuous:\n",
    "                X_index_c_con = self.X[item].values[np.where(self.y == c)]\n",
    "                X_index_c_con_mean = np.mean(X_index_c_con)\n",
    "                X_index_c_con_var = np.var(X_index_c_con)\n",
    "                likelihood_con[item] = {\"mean\": X_index_c_con_mean, \"var\": X_index_c_con_var}\n",
    "            # Calculate likelihood of every uncontinuous attribute\n",
    "            likelihood_uncon = {}\n",
    "            for item in self.uncontinuous:\n",
    "                X_index_c_uncon = self.X[item].values[np.where(self.y == c)]\n",
    "                classes = np.unique(X_index_c_uncon)\n",
    "                likelihood = {}\n",
    "                for class_item in classes:\n",
    "                    likelihood[class_item] = X_index_c_uncon[np.where(X_index_c_uncon == class_item)].shape[0] / X_index_c_uncon.shape[0]\n",
    "                likelihood_uncon[item] = {\"likelihoods\": likelihood}\n",
    "                    # print(X_index_c_uncon[np.where(X_index_c_uncon == class_item)].shape[0])\n",
    "            self.parameters[c] = {\"prior\": prior, \"likelihood_con\": likelihood_con, \"likelihood_uncon\": likelihood_uncon}    \n",
    "        return self.parameters\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calculate post probability of every class : P(C_i | x_1 x_2 ... x_n) = P(C_i)P(x_1 | C_i)P(x_2 | C_i)...P(x_n | C_i)\n",
    "        output = []\n",
    "        m_samples = X.shape[0]\n",
    "        # For every sample\n",
    "        for i in range(m_samples):\n",
    "            max = float('-inf')\n",
    "            chosen = 0\n",
    "            for c in self.classes:\n",
    "                prior = self.parameters[c][\"prior\"]\n",
    "                likelihood_log = 0\n",
    "                # For every uncontinuous attribute\n",
    "                for a in self.uncontinuous:\n",
    "                    x = X[a][i : i + 1].values\n",
    "                    probability = self.parameters[c][\"likelihood_uncon\"][a][\"likelihoods\"][x[0]]\n",
    "                    likelihood_log += np.log(probability)\n",
    "                # For every continuous attribute\n",
    "                for a in self.continuous:\n",
    "                    mean = self.parameters[c][\"likelihood_con\"][a][\"mean\"]\n",
    "                    var = self.parameters[c][\"likelihood_con\"][a][\"var\"]\n",
    "                    x = X[a][i : i + 1].values\n",
    "                    probability = self.gaussian_probability(mean, var, x[0])\n",
    "                    likelihood_log += np.log(probability)\n",
    "                post_log = np.log(prior) + likelihood_log\n",
    "                if post_log > max:\n",
    "                    max = post_log\n",
    "                    chosen = c\n",
    "            output.append(chosen)\n",
    "        return output\n",
    "\n",
    "    def gaussian_probability(self, mean, var, x):\n",
    "        eps = 1e-4\n",
    "        numerator = np.exp(-(x - mean) ** 2 / (2 * var + eps))\n",
    "        denominator = np.sqrt(2 * np.pi * var + eps)\n",
    "        result = numerator / denominator\n",
    "        return result\n",
    "\n",
    "    def test(self, X, y):\n",
    "        output = self.predict(X)\n",
    "        right_count = 0\n",
    "        m_samples = X.shape[0]\n",
    "        for i in range(m_samples):\n",
    "            if output[i] == y.values[i]:\n",
    "                right_count += 1\n",
    "        return right_count / m_samples \n"
   ]
  },
  {
   "source": [
    "## Train models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Decide what fields we want to process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_param_name = 'price_classification'\n",
    "price_range = 'price_range'"
   ]
  },
  {
   "source": [
    "### Split training set and test set into input and output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop(output_param_name,axis=1,inplace=False).drop(price_range,axis=1,inplace=False)\n",
    "y_train = train_data[output_param_name]\n",
    "x_test = test_data.drop(output_param_name,axis=1,inplace=False).drop(price_range,axis=1,inplace=False)\n",
    "y_test = test_data[output_param_name]"
   ]
  },
  {
   "source": [
    "#### Check whether the split works correctly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n1569           1494     0          2.4         0   6       1           3   \n\n      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n1569    0.9         93        7  17        944      1003  1208    14    13   \n\n      talk_time  three_g  touch_screen  wifi  \n1569         17        1             1     0  \n"
     ]
    }
   ],
   "source": [
    "print(x_train[0 : 1])\n",
    "# print(y_train)\n",
    "# print(x_test)\n",
    "# print(y_test)"
   ]
  },
  {
   "source": [
    "### Train Logistic Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "theta = logistic_regression.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "source": [
    "#### Print model parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    Model Parameters\n0        -135.541899\n1          25.564515\n2         -11.081706\n3         -30.352189\n4         -12.951177\n5         -66.969190\n6         -11.540574\n7        -523.644637\n8         -12.833274\n9       -1289.530460\n10        -86.409564\n11       -192.660687\n12         48.538151\n13        -19.997391\n14        268.391640\n15       -286.155834\n16       -112.939361\n17       -265.969041\n18        -15.630582\n19        -13.931820\n20        -10.827900\n"
     ]
    }
   ],
   "source": [
    "theta_table = pd.DataFrame({'Model Parameters': theta.flatten()})\n",
    "print(theta_table)"
   ]
  },
  {
   "source": [
    "### Train Naive Bayes Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Continuous attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = [\n",
    "    'battery_power',\n",
    "    'clock_speed',\n",
    "    'fc',\n",
    "    'int_memory',\n",
    "    'm_dep',\n",
    "    'mobile_wt',\n",
    "    'pc',\n",
    "    'px_height',\n",
    "    'px_width',\n",
    "    'ram',\n",
    "    'sc_h',\n",
    "    'sc_w',\n",
    "    'talk_time'\n",
    "]\n",
    "uncontinuous = [\n",
    "    'blue',\n",
    "    'dual_sim',\n",
    "    'four_g',\n",
    "    'n_cores',\n",
    "    'three_g',\n",
    "    'touch_screen',\n",
    "    'wifi'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayes(continuous, uncontinuous)\n",
    "params = naive_bayes.fit(x_train, y_train)"
   ]
  },
  {
   "source": [
    "#### Print parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters of Naive Bayes Model:  {0: {'prior': 0.5, 'likelihood_con': {'battery_power': {'mean': 1169.195, 'var': 183449.47697499997}, 'clock_speed': {'mean': 1.48875, 'var': 0.6891484374999999}, 'fc': {'mean': 4.1675, 'var': 18.80194375}, 'int_memory': {'mean': 31.64625, 'var': 331.7836109375}, 'm_dep': {'mean': 0.51625, 'var': 0.08251093749999999}, 'mobile_wt': {'mean': 140.03625, 'var': 1283.7199359375}, 'pc': {'mean': 9.6225, 'var': 37.002493750000006}, 'px_height': {'mean': 593.73625, 'var': 171561.27418593748}, 'px_width': {'mean': 1200.53, 'var': 182335.3341}, 'ram': {'mean': 1233.5, 'var': 371179.87}, 'sc_h': {'mean': 12.345, 'var': 17.748475}, 'sc_w': {'mean': 5.59125, 'var': 17.5666734375}, 'talk_time': {'mean': 10.98, 'var': 29.9696}}, 'likelihood_uncon': {'blue': {'likelihoods': {0: 0.52125, 1: 0.47875}}, 'dual_sim': {'likelihoods': {0: 0.49625, 1: 0.50375}}, 'four_g': {'likelihoods': {0: 0.48875, 1: 0.51125}}, 'n_cores': {'likelihoods': {1: 0.1325, 2: 0.13375, 3: 0.12875, 4: 0.1275, 5: 0.11, 6: 0.12375, 7: 0.1175, 8: 0.12625}}, 'three_g': {'likelihoods': {0: 0.255, 1: 0.745}}, 'touch_screen': {'likelihoods': {0: 0.47875, 1: 0.52125}}, 'wifi': {'likelihoods': {0: 0.50125, 1: 0.49875}}}}, 1: {'prior': 0.5, 'likelihood_con': {'battery_power': {'mean': 1299.6725, 'var': 193394.71024374999}, 'clock_speed': {'mean': 1.5110000000000001, 'var': 0.644679}, 'fc': {'mean': 4.28375, 'var': 18.7057359375}, 'int_memory': {'mean': 32.81875, 'var': 330.1458984375}, 'm_dep': {'mean': 0.49337500000000006, 'var': 0.082793609375}, 'mobile_wt': {'mean': 140.73125, 'var': 1242.0265234375}, 'pc': {'mean': 9.96875, 'var': 36.2002734375}, 'px_height': {'mean': 692.19125, 'var': 219980.1046734375}, 'px_width': {'mean': 1308.88625, 'var': 184574.5883109375}, 'ram': {'mean': 3007.81625, 'var': 397971.71248593746}, 'sc_h': {'mean': 12.19125, 'var': 17.7971734375}, 'sc_w': {'mean': 5.87625, 'var': 19.508435937500003}, 'talk_time': {'mean': 11.145, 'var': 29.736475}}, 'likelihood_uncon': {'blue': {'likelihoods': {0: 0.50375, 1: 0.49625}}, 'dual_sim': {'likelihoods': {0: 0.485, 1: 0.515}}, 'four_g': {'likelihoods': {0: 0.46875, 1: 0.53125}}, 'n_cores': {'likelihoods': {1: 0.1225, 2: 0.12125, 3: 0.12375, 4: 0.125, 5: 0.1425, 6: 0.10625, 7: 0.13125, 8: 0.1275}}, 'three_g': {'likelihoods': {0: 0.23125, 1: 0.76875}}, 'touch_screen': {'likelihoods': {0: 0.50125, 1: 0.49875}}, 'wifi': {'likelihoods': {0: 0.47125, 1: 0.52875}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters of Naive Bayes Model: \", params)"
   ]
  },
  {
   "source": [
    "## Test models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Test Logistic Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of Logistic Regression Model: 0.79\n"
     ]
    }
   ],
   "source": [
    "accuracy_result_1 = logistic_regression.test(x_test.values, y_test.values)\n",
    "print('Accuracy of Logistic Regression Model: {:.2f}' .format(accuracy_result_1))"
   ]
  },
  {
   "source": [
    "### Test Naive Bayes Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of Naive Bayes Model: 0.94\n"
     ]
    }
   ],
   "source": [
    "accuracy_result_2 = naive_bayes.test(x_test, y_test)\n",
    "print('Accuracy of Naive Bayes Model: {:.2f}' .format(accuracy_result_2))"
   ]
  }
 ]
}