{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit (conda)",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "fcdafa320b1bd52415b4da26a3e91d8c55e0b68a992d8fe533e9215398eb0247"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import 3rd party dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 88,
   "outputs": []
  },
  {
   "source": [
    "## Load training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data = pd.read_csv(\"archive/train.csv\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 89,
   "outputs": []
  },
  {
   "source": [
    "## Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Convert labels into to two classes: low (0, 1) and high (2, 3)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price_classification\"] = np.where(data[\"price_range\"] <= 1, 0, 1)"
   ]
  },
  {
   "source": [
    "#### Split the original ‘train.csv’ into ‘train.csv’, ‘valid.csv’ and ‘test.csv’ with the ratio of 0.8 : 0.1 : 0.1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data\n",
    "y = data[\"price_range\"]\n",
    "x_train, x_tmp, y_train, y_tmp = train_test_split(x, y, test_size = 0.2, random_state = 101, stratify = y)\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(x_tmp, y_tmp, test_size = 0.5, random_state = 101, stratify = y_tmp)"
   ]
  },
  {
   "source": [
    "#### Test whether the split workd correctly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1600, 22)\n(200, 22)\n(200, 22)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "source": [
    "#### Write the data back to the csv file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(\"train.csv\")\n",
    "x_test.to_csv(\"test.csv\")\n",
    "x_valid.to_csv(\"valid.csv\")"
   ]
  },
  {
   "source": [
    "## Model Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### The Sigmoid function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 94,
   "outputs": []
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, learning_rate=.1, n_iterations=6000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def initialize_weights(self, n_features):\n",
    "        limit = np.sqrt(1 / n_features)\n",
    "        w = np.random.uniform(-limit, limit, (n_features, 1))\n",
    "        b = 0\n",
    "        # Insert 0 as w_0\n",
    "        self.w = np.insert(w, 0, b, axis=0)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        normal_X = normalize(X, norm = 'max')\n",
    "        m_samples, n_features = normal_X.shape\n",
    "        self.initialize_weights(n_features)\n",
    "        # Insert a column of 1 as x_0\n",
    "        normal_X = np.insert(normal_X, 0, 1, axis=1)\n",
    "        y = np.reshape(y, (m_samples, 1))\n",
    "        for i in range(self.n_iterations):\n",
    "            h_x = normal_X.dot(self.w)\n",
    "            y_pred = sigmoid(h_x)\n",
    "            w_grad = normal_X.T.dot(y_pred - y)\n",
    "            self.w = self.w - self.learning_rate * w_grad\n",
    "        return self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        normal_X = normalize(X, norm = 'max')\n",
    "        normal_X = np.insert(normal_X, 0, 1, axis=1)\n",
    "        h_x = normal_X.dot(self.w)\n",
    "        y_pred = np.round(sigmoid(h_x))\n",
    "        return y_pred.astype(int)\n",
    "\n",
    "    def test(self, X, y):\n",
    "        normal_X = normalize(X, norm = 'max')\n",
    "        m_samples = normal_X.shape[0]\n",
    "        normal_X = np.insert(normal_X, 0, 1, axis=1)\n",
    "        h_x = normal_X.dot(self.w)\n",
    "        y_pred = np.round(sigmoid(h_x))\n",
    "        right_count = 0\n",
    "        for i in range(m_samples):\n",
    "            if y_pred[i] == y[i]:\n",
    "                right_count += 1\n",
    "        return right_count / m_samples "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 95,
   "outputs": []
  },
  {
   "source": [
    "### Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = {}\n",
    "        for i, c in enumerate(self.classes):\n",
    "            # Calculate the mean value, variance and prior probability of every class\n",
    "            X_Index_c = X[np.where(y == c)]\n",
    "            X_index_c_mean = np.mean(X_Index_c, axis=0, keepdims=True)\n",
    "            X_index_c_var = np.var(X_Index_c, axis=0, keepdims=True)\n",
    "            parameters = {\"mean\": X_index_c_mean, \"var\": X_index_c_var, \"prior\": X_Index_c.shape[0] / X.shape[0]}\n",
    "            self.parameters[\"class\" + str(c)] = parameters\n",
    "\n",
    "    def _pdf(self, X, classes):\n",
    "        # 一维高斯分布的概率密度函数\n",
    "        # eps为防止分母为0\n",
    "        eps = 1e-4\n",
    "        mean = self.parameters[\"class\" + str(classes)][\"mean\"]\n",
    "        var = self.parameters[\"class\" + str(classes)][\"var\"]\n",
    "\n",
    "        # 取对数防止数值溢出\n",
    "        # numerator.shape = [m_sample,feature]\n",
    "        numerator = np.exp(-(X - mean) ** 2 / (2 * var + eps))\n",
    "        denominator = np.sqrt(2 * np.pi * var + eps)\n",
    "\n",
    "        # 朴素贝叶斯假设(每个特征之间相互独立)\n",
    "        # P(x1,x2,x3|Y) = P(x1|Y)*P(x2|Y)*P(x3|Y),取对数相乘变为相加\n",
    "        # result.shape = [m_sample,1]\n",
    "        result = np.sum(np.log(numerator / denominator), axis=1, keepdims=True)\n",
    "\n",
    "        return result.T\n",
    "\n",
    "    def _predict(self, X):\n",
    "        # 计算每个种类的概率P(Y|x1,x2,x3) =  P(Y)*P(x1|Y)*P(x2|Y)*P(x3|Y)\n",
    "        output = []\n",
    "        for y in range(self.classes.shape[0]):\n",
    "            prior = np.log(self.parameters[\"class\" + str(y)][\"prior\"])\n",
    "            posterior = self._pdf(X, y)\n",
    "            prediction = prior + posterior\n",
    "            output.append(prediction)\n",
    "        return output\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 取概率最大的类别返回预测值\n",
    "        output = self._predict(X)\n",
    "        output = np.reshape(output, (self.classes.shape[0], X.shape[0]))\n",
    "        prediction = np.argmax(output, axis=0)\n",
    "        return prediction"
   ]
  },
  {
   "source": [
    "## Train models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Decide what fields we want to process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_param_name = 'price_classification'\n",
    "price_range = 'price_range'"
   ]
  },
  {
   "source": [
    "### Split training set and test set into input and output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop([output_param_name],axis=1,inplace=False).drop([price_range],axis=1,inplace=False).values\n",
    "y_train = train_data[[output_param_name]].values\n",
    "x_test = test_data.drop([output_param_name],axis=1,inplace=False).drop([price_range],axis=1,inplace=False).values\n",
    "y_test = test_data[[output_param_name]].values"
   ]
  },
  {
   "source": [
    "#### Check whether the split works correctly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.130e+03 1.000e+00 2.500e+00 ... 1.000e+00 0.000e+00 0.000e+00]\n [6.330e+02 1.000e+00 1.400e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n [1.576e+03 1.000e+00 2.000e+00 ... 1.000e+00 0.000e+00 1.000e+00]\n ...\n [5.010e+02 0.000e+00 2.300e+00 ... 1.000e+00 0.000e+00 1.000e+00]\n [7.190e+02 1.000e+00 5.000e-01 ... 1.000e+00 1.000e+00 1.000e+00]\n [6.150e+02 1.000e+00 5.000e-01 ... 1.000e+00 0.000e+00 0.000e+00]]\n[[0]\n [0]\n [0]\n ...\n [0]\n [1]\n [0]]\n[[6.150e+02 1.000e+00 2.500e+00 ... 1.000e+00 0.000e+00 0.000e+00]\n [1.821e+03 1.000e+00 1.200e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n [9.560e+02 0.000e+00 5.000e-01 ... 1.000e+00 1.000e+00 0.000e+00]\n ...\n [1.483e+03 1.000e+00 2.200e+00 ... 1.000e+00 0.000e+00 0.000e+00]\n [1.467e+03 1.000e+00 5.000e-01 ... 1.000e+00 1.000e+00 1.000e+00]\n [7.940e+02 1.000e+00 5.000e-01 ... 1.000e+00 1.000e+00 0.000e+00]]\n[[1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [0]\n [0]\n [0]\n [0]\n [1]\n [1]\n [1]\n [1]\n [1]\n [0]\n [0]\n [1]\n [1]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [0]\n [1]\n [0]\n [0]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [0]\n [1]\n [0]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [1]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [1]\n [0]\n [1]\n [1]\n [0]\n [1]\n [0]\n [0]\n [1]\n [1]\n [0]\n [0]\n [0]\n [0]\n [0]\n [1]\n [0]\n [0]\n [0]\n [0]\n [0]\n [1]\n [0]\n [0]\n [1]\n [1]\n [1]\n [1]\n [1]\n [1]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [1]\n [1]\n [0]\n [0]\n [1]\n [1]\n [0]\n [1]\n [1]\n [0]\n [1]\n [1]\n [1]\n [0]\n [0]\n [0]\n [1]\n [0]\n [0]\n [0]\n [0]\n [0]\n [0]\n [1]\n [1]\n [0]\n [0]\n [1]\n [1]\n [0]\n [0]\n [0]\n [1]\n [1]\n [1]\n [0]\n [1]\n [1]\n [0]\n [0]\n [1]\n [1]\n [1]\n [1]\n [0]\n [0]\n [1]\n [1]\n [0]\n [1]\n [0]\n [0]\n [1]\n [1]\n [0]\n [0]\n [0]\n [0]\n [1]\n [1]\n [0]\n [1]\n [1]\n [0]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [0]\n [0]\n [0]\n [1]\n [1]\n [0]\n [1]\n [1]\n [1]\n [1]\n [0]\n [1]\n [0]\n [1]\n [1]\n [0]\n [1]\n [1]\n [1]\n [0]\n [0]\n [0]\n [0]\n [1]\n [1]\n [0]\n [1]\n [0]\n [1]\n [1]\n [0]\n [0]\n [0]\n [1]\n [1]\n [0]\n [1]\n [0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)\n",
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "source": [
    "### Train Logistic Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "theta = logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "source": [
    "#### Print model parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    Model Parameters\n0        -144.631006\n1          12.762937\n2          -9.087355\n3         -23.561154\n4          -9.748242\n5         -54.191296\n6          -8.195112\n7        -474.453166\n8          -9.731858\n9       -1244.062972\n10        -70.876019\n11       -146.039302\n12         48.570463\n13        -28.216827\n14        283.735354\n15       -200.736174\n16        -70.411975\n17       -209.759570\n18        -10.596741\n19         -9.785571\n20         -8.690528\n"
     ]
    }
   ],
   "source": [
    "theta_table = pd.DataFrame({'Model Parameters': theta.flatten()})\n",
    "print(theta_table)"
   ]
  },
  {
   "source": [
    "## Test models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Test Logistic Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "accuracy_result = logistic_regression.test(x_test, y_test)\n",
    "print('Accuracy: {:.2f}' .format(accuracy_result))"
   ]
  }
 ]
}